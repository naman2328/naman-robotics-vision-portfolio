<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Industrial Vision Simulator | Naman Sharma</title>

  <link rel="stylesheet" href="css/style.css">

  <!-- OCR ENGINE (WEB SIMULATION ONLY) -->
  <script src="https://unpkg.com/tesseract.js@5.0.4/dist/tesseract.min.js"></script>
</head>

<body>

<main class="container simulator">

  <!-- ================= NAV ================= -->
  <nav class="section">
    <a href="index.html" class="sticky-back-btn">← Back to Home</a>
  </nav>

  <!-- ================= HEADER ================= -->
  <header class="section">
    <span class="badge">INSPECTION SIMULATOR</span>
    <h1>Industrial Vision Dashboard (Web Simulator)</h1>
  </header>

  <!-- ================= DISCLAIMER ================= -->
  <section class="section card warning">
    <p>
      ⚠️ <strong>Important:</strong> This is a browser-based simulator demonstrating
      system workflow and inspection logic only.
      <br><br>
      The <strong>actual production system</strong> runs as a Qt application using
      PaddleOCR, barcode decoding, and industrial cameras.
      This simulator mirrors the logic and UI behavior, not the production OCR engine.
    </p>
  </section>

  <!-- ================= CAMERA + STATUS ================= -->
  <section class="section grid">

    <!-- CAMERA -->
    <article class="card">
      <h2>Camera Feed (Webcam)</h2>

      <div class="camera-wrapper">
        <video id="video" autoplay muted playsinline></video>
        <canvas id="overlay"></canvas>
      </div>

      <p class="hint">Click & drag to define ROI</p>
    </article>

    <!-- STATUS -->
    <article class="card">
      <h2>Inspection Status</h2>

      <ul class="status-list">
        <li>System: <span id="systemStatus" class="ok">READY</span></li>
        <li>Detected Text: <span id="ocrText">---</span></li>
        <li>Result: <span id="resultText">---</span></li>
        <li>Confidence: <span id="confidence">---</span></li>
        <li>Cycle Time: <span id="cycleTime">---</span></li>
      </ul>

      <button class="button" onclick="runOCR()">Single Capture</button>
    </article>

  </section>

  <!-- ================= LOGS ================= -->
  <section class="section card">
    <h2>System Logs</h2>
    <div id="logs" class="log-panel"></div>
  </section>

  <!-- ================= LOGIC ================= -->
  <section class="section card">
    <h2>Inspection Logic (Mirrored)</h2>
    <p class="section-text">
      OCR → Text normalization → Fuzzy matching → OK / NG decision →
      Confidence & timing → Logging.
      <br><br>
      The same decision flow is used in the Qt-based production system,
      while the OCR backend differs for platform compatibility.
    </p>
  </section>

</main>

<!-- ================= SCRIPT ================= -->
<script>
/* ================= CONFIG ================= */
const expectedEntries = ["ABC123", "LOT45"];
const MATCH_THRESHOLD = 0.95;

/* ================= STATE ================= */
let roi = null;
let drawing = false;
let startX, startY;

/* ================= ELEMENTS ================= */
const video = document.getElementById("video");
const canvas = document.getElementById("overlay");
const ctx = canvas.getContext("2d");

const systemStatus = document.getElementById("systemStatus");
const ocrTextEl = document.getElementById("ocrText");
const resultText = document.getElementById("resultText");
const confidenceEl = document.getElementById("confidence");
const cycleTimeEl = document.getElementById("cycleTime");
const logs = document.getElementById("logs");

/* ================= CAMERA ================= */
navigator.mediaDevices.getUserMedia({ video: true })
  .then(stream => {
    video.srcObject = stream;
    video.onloadedmetadata = () => {
      canvas.width = video.videoWidth;
      canvas.height = video.videoHeight;
      log("Webcam stream started");
    };
  })
  .catch(() => alert("Camera access denied"));

/* ================= ROI DRAW ================= */
canvas.addEventListener("mousedown", e => {
  drawing = true;
  startX = e.offsetX;
  startY = e.offsetY;
});

canvas.addEventListener("mousemove", e => {
  if (!drawing) return;
  redraw();
  drawRect(startX, startY, e.offsetX - startX, e.offsetY - startY, "#facc15");
});

canvas.addEventListener("mouseup", e => {
  drawing = false;
  roi = {
    x: Math.min(startX, e.offsetX),
    y: Math.min(startY, e.offsetY),
    w: Math.abs(e.offsetX - startX),
    h: Math.abs(e.offsetY - startY)
  };
  log("ROI defined");
  redraw();
});

function redraw() {
  ctx.clearRect(0, 0, canvas.width, canvas.height);
  if (roi) drawRect(roi.x, roi.y, roi.w, roi.h, "#22c55e");
}

function drawRect(x, y, w, h, color) {
  ctx.strokeStyle = color;
  ctx.lineWidth = 2;
  ctx.strokeRect(x, y, w, h);
}

/* ================= TEXT LOGIC ================= */
function normalize(text) {
  return text.toLowerCase().replace(/\s/g, "").replace(/[.,]/g, "");
}

function similarity(a, b) {
  let matches = 0;
  for (let i = 0; i < Math.min(a.length, b.length); i++) {
    if (a[i] === b[i]) matches++;
  }
  return matches / Math.max(a.length, b.length);
}

function isMatch(expected, detected) {
  const exp = normalize(expected);
  return detected.some(d => similarity(exp, normalize(d)) >= MATCH_THRESHOLD);
}

/* ================= OCR ================= */
async function runOCR() {
  if (!roi) return alert("Define ROI first");

  systemStatus.textContent = "PROCESSING";
  log("OCR cycle started");

  const t0 = performance.now();

  const temp = document.createElement("canvas");
  temp.width = roi.w;
  temp.height = roi.h;
  temp.getContext("2d").drawImage(
    video, roi.x, roi.y, roi.w, roi.h, 0, 0, roi.w, roi.h
  );

  const result = await Tesseract.recognize(temp, "eng");
  const words = result.data.words.map(w => w.text).filter(Boolean);

  ocrTextEl.textContent = words.join(" | ") || "(no text)";
  confidenceEl.textContent = result.data.confidence.toFixed(1) + "%";

  const matched = expectedEntries.filter(e => isMatch(e, words));
  const status = matched.length === expectedEntries.length ? "OK" : "NG";

  resultText.textContent = status;
  resultText.className = status === "OK" ? "ok" : "fail";

  cycleTimeEl.textContent =
    ((performance.now() - t0) / 1000).toFixed(2) + " s";

  systemStatus.textContent = "READY";
  log(`OCR completed → ${status}`);
}

/* ================= LOGGING ================= */
function log(msg) {
  logs.innerHTML += `[${new Date().toLocaleTimeString()}] ${msg}<br>`;
  logs.scrollTop = logs.scrollHeight;
}
</script>

</body>
</html>
